{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85d84c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model Loading...\n",
      "[INFO] Model Loaded...\n",
      "[INFO] Model Loading...\n",
      "[INFO] Model Loaded...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pynput.keyboard import Controller,Key\n",
    "from playsound import playsound\n",
    "\n",
    "keyboard=Controller()\n",
    "\n",
    "   \n",
    "cap_path=\"Videos\\\\video8.mp4\"\n",
    "Yolo_v4_model_path=\"Models\\\\yolov4_road_model\\\\yolov4_road_v2_final.weights\"\n",
    "Yolo_v4_cfg_path=\"Models\\\\yolov4_road_model\\\\yolov4_road.cfg\"\n",
    "color=(255,0,0)\n",
    "view_color=(1,1,1)\n",
    "labels=[\"road\"]\n",
    "\n",
    "print(\"[INFO] Road Model Loading...\")\n",
    "model=cv2.dnn.readNetFromDarknet(Yolo_v4_cfg_path, Yolo_v4_model_path)\n",
    "print(\"[INFO] Road Model Loaded...\")\n",
    "\n",
    "layers=model.getLayerNames()\n",
    "for layer in model.getUnconnectedOutLayers():\n",
    "    output_layer=[layers[layer-1]]\n",
    "    \n",
    "\n",
    "Person_Yolo_v4_model_path=\"Models\\\\yolov4_three_class_model\\\\yolov4_v2_final.weights\"\n",
    "Person_Yolo_v4_cfg_path=\"Models\\\\yolov4_three_class_model\\\\yolov4_v2.cfg\"\n",
    "person_color=(0,255,0)\n",
    "person_labels=[\"person\",\"face\",\"hand\"]\n",
    "\n",
    "print(\"[INFO] Person Model Loading...\")\n",
    "person_model=cv2.dnn.readNetFromDarknet(Person_Yolo_v4_cfg_path, Person_Yolo_v4_model_path)\n",
    "print(\"[INFO] Person Model Loaded...\")\n",
    "\n",
    "person_layers=person_model.getLayerNames()\n",
    "for layer in person_model.getUnconnectedOutLayers():\n",
    "    person_output_layer=[layers[layer-1]]\n",
    "    \n",
    "            \n",
    "cap=cv2.VideoCapture(cap_path)\n",
    "\n",
    "ret,frame=cap.read()\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "imageOrj=frame[0:height,int(0+(width/4)):int(width-(width/4)),:]\n",
    "bboxArea=imageOrj.shape[0]*imageOrj.shape[1]\n",
    "t_=2\n",
    "time=t_\n",
    "refresh_time=0\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    if ret==True:\n",
    "        image=frame[0:height,int(0+(width/4)):int(width-(width/4)),:]\n",
    "        \n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        img_blob=cv2.dnn.blobFromImage(frame, 1/255, (416,416), swapRB= True, crop= False)  \n",
    "        \n",
    "        \n",
    "        \n",
    "        model.setInput(img_blob)\n",
    "        \n",
    "        detection_layers=model.forward(output_layer)\n",
    "\n",
    "\n",
    "        for detection_layer in detection_layers:\n",
    "            for object_detection in detection_layer:\n",
    "\n",
    "                scores=object_detection[5:]\n",
    "                predicted_id=np.argmax(scores)\n",
    "                confidence=scores[predicted_id]\n",
    "\n",
    "                if confidence > 0.75:\n",
    "\n",
    "                    label=labels[predicted_id]\n",
    "                    bounding_box=object_detection[0:4]*np.array([width,height,width,height])\n",
    "                    (box_center_x, box_center_y, box_width, box_height)= bounding_box.astype(\"int\")\n",
    "\n",
    "                    start_x=int(box_center_x-(box_width/2))\n",
    "                    start_y=int(box_center_y-(box_height/2))\n",
    "\n",
    "                    end_x=start_x+box_width\n",
    "                    end_y=start_y+box_height\n",
    "\n",
    "#                     print(\"{} {} {} {}\".format(box_center_x, box_center_y, box_width, box_height))\n",
    "#                     print(\"{} {} {} {}\".format(start_x, start_y, end_x, end_y))\n",
    "\n",
    "                    label=\"{}: {:.2f}%\".format(label, confidence*100)\n",
    "#                     print(\"predicted object {}\".format(label))\n",
    "\n",
    "                    cv2.rectangle(frame, (start_x, start_y),(end_x, end_y), color, 1) \n",
    "                    cv2.putText(frame, label, (start_x,start_y+10),cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)\n",
    "\n",
    "        \n",
    "        person_model.setInput(img_blob)\n",
    "        \n",
    "        person_detection_layers=person_model.forward(person_output_layer)\n",
    "\n",
    "\n",
    "        for person_detection_layer in person_detection_layers:\n",
    "            for person_object_detection in person_detection_layer:\n",
    "\n",
    "                person_scores=person_object_detection[5:]\n",
    "                person_predicted_id=np.argmax(person_scores)\n",
    "                person_confidence=person_scores[person_predicted_id]\n",
    "\n",
    "                if person_confidence > 0.80:\n",
    "\n",
    "                    person_label=person_labels[person_predicted_id]\n",
    "                    person_bounding_box=person_object_detection[0:4]*np.array([width,height,width,height])\n",
    "                    (box_center_x, box_center_y, box_width, box_height)= person_bounding_box.astype(\"int\")\n",
    "\n",
    "                    person_start_x=int(box_center_x-(box_width/2))\n",
    "                    person_start_y=int(box_center_y-(box_height/2))\n",
    "\n",
    "                    person_end_x=person_start_x+box_width\n",
    "                    person_end_y=person_start_y+box_height\n",
    "\n",
    "#                     print(\"{} {} {} {}\".format(box_center_x, box_center_y, box_width, box_height))\n",
    "#                     print(\"{} {} {} {}\".format(start_x, start_y, end_x, end_y))\n",
    "\n",
    "                    person_label=\"{}: {:.2f}%\".format(person_label, person_confidence*100)\n",
    "#                     print(\"predicted object {}\".format(label))\n",
    "\n",
    "                    cv2.rectangle(frame, (person_start_x, person_start_y),(person_end_x, person_end_y), person_color, 1) \n",
    "                    cv2.putText(frame, person_label, (person_start_x,person_start_y+10),cv2.FONT_HERSHEY_SIMPLEX, 0.3, person_color, 1)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        diff=cv2.subtract(imageOrj,image)\n",
    "\n",
    "        ret,thresh=cv2.threshold(diff[:,:,0],0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        cnts=cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "\n",
    "        thresh=cv2.dilate(thresh,None,iterations=2)\n",
    "        if not cnts:\n",
    "            c=bboxArea\n",
    "            ratio=0.0\n",
    "            c_max=0.0\n",
    "        else:\n",
    "            c=max(cnts,key=cv2.contourArea)\n",
    "            ratio=cv2.contourArea(c)/bboxArea\n",
    "            c_max=cv2.contourArea(c)\n",
    "        # if ratio>0.2 and ratio<0.3:\n",
    "        #     keyboard.press(Key.space)\n",
    "        # # if ratio>0.65:\n",
    "        # #     keyboard.press(ord(\"q\"))\n",
    "        time-=1\n",
    "        if time==0:\n",
    "            ret,orj_frame=cap.read()\n",
    "            imageOrj=orj_frame[0:height,int(0+(width/4)):int(width-(width/4)),:]\n",
    "            bboxArea=imageOrj.shape[0]*imageOrj.shape[1]\n",
    "            time=t_\n",
    "            refresh_time+=1\n",
    "            \n",
    "        cv2.putText(frame,\"ImageOrj Refreshed: \"+str(refresh_time)+\" times\",(10,455),cv2.FONT_HERSHEY_SIMPLEX,0.3,(175,175,175),1)\n",
    "   \n",
    "        cv2.putText(frame,(\"TimeLeft: \"+str(time)),(int(width-(width/4)+5),25),cv2.FONT_HERSHEY_SIMPLEX,0.3,(175,175,175),1)\n",
    "\n",
    "        if ratio>0.10:\n",
    "            playsound (\"Voices\\\\radyoaktif.mp3\")\n",
    "            cv2.putText(frame,\"Attention!!!\",(int(width-(width/4)+5),240),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,0,255),2)\n",
    "\n",
    "\n",
    "\n",
    "        # if time.sleep(5) is False:\n",
    "        #     ret,frame=cam.read_frame()\n",
    "        #     imageOrj=frame[0:480,160:480,:]\n",
    "        #     bboxArea=imageOrj.shape[0]*imageOrj.shape[1]\n",
    "        #     print(\"Ä°mageOrj Refreshed\")\n",
    "\n",
    "\n",
    "        cv2.putText(diff,(\"ratio: \"+str(ratio)),(10,10),cv2.FONT_HERSHEY_SIMPLEX,0.3,(175,175,175),1)\n",
    "        cv2.imshow(\"diff\",diff)\n",
    "        cv2.imshow(\"ImageOrj\",imageOrj)\n",
    "\n",
    "        cv2.putText(thresh,str(c_max),(10,10),cv2.FONT_HERSHEY_SIMPLEX,0.3,(175,175,175),1)\n",
    "        cv2.imshow(\"thresh\",thresh)\n",
    "\n",
    "        cv2.rectangle(frame,(int(0+(width/4)),0),(int(width-(width/4)),height),view_color,1)\n",
    "        cv2.putText(frame,\"@author: muhammetsarican\",(10,25),cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,0.4,(255,255,255),1)\n",
    "#         cv2.imshow(\"Frame\",frame)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        cv2.imshow('frame',frame)\n",
    "        key=cv2.waitKey(1)&0xff\n",
    "\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "cap.release()        \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
